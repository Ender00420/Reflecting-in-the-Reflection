{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import configparser\n",
    "import json\n",
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "\n",
    "api_key = ''\n",
    "with open('../openai.txt', 'r') as file:\n",
    "    api_key = file.read().replace('\\n', '')\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_models():\n",
    "    \"\"\"\n",
    "    List all available models in the OpenAI API.\n",
    "    \"\"\"\n",
    "    models = client.models.list()\n",
    "    print(\"Available models:\")\n",
    "\n",
    "    model_ids = []\n",
    "    for model in models.data:\n",
    "        model_ids.append(model.id)\n",
    "\n",
    "    model_ids.sort()\n",
    "    for model_id in model_ids:\n",
    "        print(model_id)\n",
    "\n",
    "# list_models(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costs(prompt_tokens, completion_tokens):\n",
    "    \"\"\"\n",
    "    Calculate the costs based on the number of tokens used.\n",
    "    Args:\n",
    "        prompt_tokens (int): The number of prompt tokens used.\n",
    "        completion_tokens (int): The number of completion tokens used.\n",
    "    Returns:\n",
    "        float: The total cost in dollars.\n",
    "    \"\"\"\n",
    "    if model_used == 'gpt-4o-mini':\n",
    "        price_per_1m_input_tokens = 0.15\n",
    "        price_per_1m_output_tokens = 0.6\n",
    "    elif model_used == 'gpt-4o':\n",
    "        price_per_1m_input_tokens = 2.5\n",
    "        price_per_1m_output_tokens = 10\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Model not set or not supported for cost calculation.\")\n",
    "    total_cost = ((prompt_tokens / 1000000) * price_per_1m_input_tokens) + \\\n",
    "        ((completion_tokens / 1000000) * price_per_1m_output_tokens)\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_upload(location):\n",
    "    \"\"\"\n",
    "    Upload a file to the OpenAI API.\n",
    "    Args:\n",
    "        location (str): The file path to upload.\n",
    "    Returns:\n",
    "        file: The uploaded file object.\n",
    "    \"\"\"\n",
    "    with open(location, \"rb\") as file:\n",
    "        file = client.files.create(\n",
    "            file=file,\n",
    "            purpose=\"user_data\"\n",
    "        )\n",
    "\n",
    "    print(\"File uploaded successfully.\")\n",
    "    return file\n",
    "\n",
    "\n",
    "def file_delete(file_id):\n",
    "    \"\"\"\n",
    "    Delete a file from the OpenAI API.\n",
    "    Args:\n",
    "        file_id (str): The ID of the file to delete.\n",
    "    Returns:\n",
    "        bool: True if the file was deleted successfully, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.files.delete(file_id)\n",
    "        print(\"File deleted successfully.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting file: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def list_files():\n",
    "    \"\"\"\n",
    "    List all files uploaded to the OpenAI API.\n",
    "    \"\"\"\n",
    "    files = client.files.list()\n",
    "    print(\"Available files:\")\n",
    "    for file in files.data:\n",
    "        print(file.id, file.filename, file.status)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prompts(file_path):\n",
    "    config = configparser.ConfigParser(allow_no_value=True, delimiters=(\"=\"))\n",
    "    config.optionxform = str\n",
    "    config.read(file_path)\n",
    "\n",
    "    prompts = {}\n",
    "    for section in config.sections():\n",
    "        prompts[section] = \"\\n\".join(\n",
    "            [f\"{key}{value}\" for key, value in config.items(section)])\n",
    "    return prompts\n",
    "\n",
    "\n",
    "def replace_variables(string, **kwargs):\n",
    "    return string.format(**kwargs)\n",
    "\n",
    "\n",
    "def read_files(file_paths):\n",
    "    json_file = None\n",
    "    txt_file = None\n",
    "    for filename in os.listdir(file_paths):\n",
    "        if filename.endswith('.json'):\n",
    "            json_file = filename\n",
    "        elif filename.endswith('.txt'):\n",
    "            txt_file = filename\n",
    "\n",
    "    if json_file is None or txt_file is None:\n",
    "        raise ValueError(\"Required files not found in the directory.\")\n",
    "\n",
    "    settings = {}\n",
    "    prompts = {}\n",
    "\n",
    "    with open(os.path.join(file_paths, json_file), 'r') as f:\n",
    "        settings = json.load(f)\n",
    "\n",
    "    prompts = load_prompts(os.path.join(file_paths, txt_file))\n",
    "\n",
    "    return settings, prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(assistant_history, user_history):\n",
    "    \"\"\"\n",
    "    Call the OpenAI API to get a response based on the provided system and user prompts.\n",
    "    Args:\n",
    "        assistant_history (str): The assistant's previous responses.\n",
    "        user_history (str): The user's previous responses.\n",
    "    Returns:\n",
    "        assistant_history (str): New assistant's history.\n",
    "        user_history (str): New user's history.\n",
    "        prompt_tokens (int): The number of prompt tokens used.\n",
    "        completion_tokens (int): The number of completion tokens used.\n",
    "    \"\"\"\n",
    "    retries = 0\n",
    "    while True:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_used,\n",
    "                messages=assistant_history,\n",
    "                max_completion_tokens=500\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            retries += 1\n",
    "            backoff_time = (2 ** retries) + random.random()\n",
    "            print(f\"Retrying in {backoff_time:.2f} seconds...\")\n",
    "            time.sleep(backoff_time)\n",
    "\n",
    "    prompt_tokens = response.usage.prompt_tokens\n",
    "    completion_tokens = response.usage.completion_tokens\n",
    "\n",
    "    global global_prompt_tokens, global_completion_tokens\n",
    "    global_prompt_tokens += response.usage.prompt_tokens\n",
    "    global_completion_tokens += response.usage.completion_tokens\n",
    "\n",
    "    assistant_history.append(\n",
    "        {\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "    user_history.append(\n",
    "        {\"role\": \"user\", \"content\": response.choices[0].message.content})\n",
    "\n",
    "    return assistant_history, user_history, prompt_tokens, completion_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_history(student_history, teacher_history, metadata):\n",
    "    \"\"\"\n",
    "    Store the history in a JSON file.\n",
    "    Args:\n",
    "        student_history (list): The student-teacher's history.\n",
    "        teacher_history (list): The teacher-educator's history.\n",
    "        metadata (dict): Additional metadata to store.\n",
    "    \"\"\"\n",
    "    all_dialogues = []\n",
    "\n",
    "    if os.path.exists(results):\n",
    "        with open(results, \"r\") as file:\n",
    "            try:\n",
    "                all_dialogues = json.load(file)\n",
    "                if not isinstance(all_dialogues, list):\n",
    "                    all_dialogues = [all_dialogues]\n",
    "            except json.JSONDecodeError:\n",
    "                # If the file is empty or invalid, start with an empty list\n",
    "                all_dialogues = []\n",
    "\n",
    "    # Append to the results file\n",
    "    dialogue_results = {\n",
    "        \"student\": student_history,\n",
    "        \"teacher\": teacher_history,\n",
    "        \"metadata\": metadata\n",
    "    }\n",
    "\n",
    "    all_dialogues.append(dialogue_results)\n",
    "\n",
    "    with open(results, \"w\") as file:\n",
    "        json.dump(all_dialogues, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tokens(tpt, tct, ttt, prompt_tokens, completion_tokens):\n",
    "    tpt += prompt_tokens\n",
    "    tct += completion_tokens\n",
    "    ttt += prompt_tokens + completion_tokens\n",
    "    return tpt, tct, ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def socratic_dialogue(settings, prompts, sources, attempt, max_iterations):\n",
    "    \"\"\"\n",
    "    Conduct a Socratic dialogue between a Student-Teacher and a Teacher-Educator.\n",
    "    Args:\n",
    "        settings (dict): The settings for the dialogue.\n",
    "        prompts (dict): The prompts for the dialogue.\n",
    "        sources (list): Additional sources to use in the dialogue.\n",
    "        attempt (int): The attempt number.\n",
    "        max_iterations (int): The maximum number of iterations for the dialogue.\n",
    "    \"\"\"\n",
    "    # LLM token count\n",
    "    tpt = 0\n",
    "    tct = 0\n",
    "    ttt = 0\n",
    "\n",
    "    iteration_count = 0\n",
    "\n",
    "    # Add the system prompts\n",
    "    st_history = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompts[\"student_teacher_start\"]\n",
    "        }\n",
    "    ]\n",
    "    te_history = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompts['teacher_educator']\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # If materials are set, use them in the dialogue\n",
    "    if settings['materials']:\n",
    "        materials = []\n",
    "        for source in sources:\n",
    "            materials.append({\"type\": \"file\", \"file\": {\"file_id\": source}})\n",
    "\n",
    "        st_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": materials\n",
    "        })\n",
    "        te_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": materials\n",
    "        })\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        iteration_count += 1\n",
    "        if i == 0:\n",
    "            st_history, te_history, pt, ct = llm_call(\n",
    "                st_history, te_history)\n",
    "\n",
    "            # Replace the starting system prompt of the Student Teacher\n",
    "            st_history[0] = {\"role\": \"system\",\n",
    "                             \"content\": prompts['student_teacher']}\n",
    "        else:\n",
    "            st_history, te_history, pt, ct = llm_call(\n",
    "                st_history, te_history)\n",
    "\n",
    "        tpt, tct, ttt = add_tokens(tpt, tct, ttt, pt, ct)\n",
    "\n",
    "        te_history, st_history, pt, ct = llm_call(\n",
    "            te_history, st_history)\n",
    "        tpt, tct, ttt = add_tokens(tpt, tct, ttt, pt, ct)\n",
    "\n",
    "        # Check if the teacher thinks the question is sufficient\n",
    "        if \"Great question!\" in te_history[-1][\"content\"]:\n",
    "            break\n",
    "    else:\n",
    "        # If the loop completes without breaking, it means the iteration limit was reached\n",
    "        st_history, te_history, pt, ct = llm_call(\n",
    "            st_history, te_history)\n",
    "        tpt, tct, ttt = add_tokens(tpt, tct, ttt, pt, ct)\n",
    "\n",
    "    metadata = {\n",
    "        \"iterations\": iteration_count,\n",
    "        \"prompt_tokens\": tpt,\n",
    "        \"completion_tokens\": tct,\n",
    "        \"total_tokens\": ttt,\n",
    "        \"attempt\": attempt,\n",
    "        \"model_used\": model_used,\n",
    "        \"student_level\": settings['student_level'],\n",
    "        \"materials\": settings['materials']\n",
    "    }\n",
    "\n",
    "    store_history(st_history, te_history, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(directory, attempts, max_iterations, topic, concepts, student_level, sources):\n",
    "    if not topic or not concepts or not student_level or not sources or not directory or not attempts:\n",
    "        raise ValueError(\"All parameters must be provided.\")\n",
    "\n",
    "    if os.path.exists(results):\n",
    "        os.remove(results)\n",
    "        with open(results, 'w') as f:\n",
    "            json.dump([], f)\n",
    "\n",
    "    print(\"Starting the generation...\")\n",
    "\n",
    "    number = 0\n",
    "    for subdir in os.listdir(directory):\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "        if not os.path.isdir(subdir_path):\n",
    "            continue\n",
    "\n",
    "        settings, prompts = read_files(subdir_path)\n",
    "\n",
    "        # Perform the replacements\n",
    "        prompts = {key: replace_variables(value, topic=topic, concepts=concepts,\n",
    "                                          student_level=student_level) for key, value in prompts.items()}\n",
    "\n",
    "        # Do x attempts\n",
    "        for i in tqdm.tqdm(range(attempts), desc=f\"Processing {subdir}\"):\n",
    "            socratic_dialogue(settings, prompts, sources,\n",
    "                              number, max_iterations)\n",
    "            number += 1\n",
    "\n",
    "    print(\"All combinations have been processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materials\n",
    "```python\n",
    "topic = \"Basics of how the internet works\"\n",
    "concepts = \"\"\"\n",
    " - Decentralization of the internet\n",
    " - Servers, datacenters and routers\n",
    " - Server vs client\n",
    " - Data packets\n",
    " - IP addresses\n",
    "\"\"\"\n",
    "student_level = \"8th or 9th grade\"\n",
    "sources = [\"file-R2qW94jP5GW8PE3JMzVf2f\", \"file-2tJuwTnPH9Pf96vDteRQ5C\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the generation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dlm: 100%|██████████| 10/10 [2:11:40<00:00, 790.05s/it] \n",
      "Processing dlw: 100%|██████████| 10/10 [08:54<00:00, 53.42s/it]\n",
      "Processing dwm: 100%|██████████| 10/10 [2:09:40<00:00, 778.10s/it] \n",
      "Processing dww: 100%|██████████| 10/10 [07:48<00:00, 46.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All combinations have been processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_used = \"gpt-4o-mini\"\n",
    "\n",
    "global_prompt_tokens = 0\n",
    "global_completion_tokens = 0\n",
    "\n",
    "# Materials\n",
    "topic = \"Basics of how the internet works\"\n",
    "concepts = \"\"\"\n",
    " - Decentralization of the internet\n",
    " - Servers, datacenters and routers\n",
    " - Server vs client\n",
    " - Data packets\n",
    " - IP addresses\n",
    "\"\"\"\n",
    "student_level = \"8th or 9th grade\"\n",
    "sources = [\"file-R2qW94jP5GW8PE3JMzVf2f\", \"file-2tJuwTnPH9Pf96vDteRQ5C\"]\n",
    "\n",
    "# Experiment settings\n",
    "directory = 'Fixed10iter/Prompts'  # Directory containing directories with prompts\n",
    "results = \"Fixed10iter/fixed10iter.json\"  # Name of the results file\n",
    "attempts = 10  # Attempts per each combination\n",
    "max_iterations = 10  # Maximum iterations for Socratic dialogue\n",
    "\n",
    "experiment(directory, attempts, max_iterations,\n",
    "           topic, concepts, student_level, sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments:\n",
    "\n",
    "Prompt combinations:\n",
    "- dialogue + student level + materials  - DLM\n",
    "- dialogue + student level + without    - DLW\n",
    "- dialogue + without + materials        - DWM\n",
    "- dialogue + without + without          - DWW\n",
    "\n",
    "Run only for the 10 iterations, then no dialogue is only the first answer, and 5 iterations can be taken from this as well for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total prompt tokens: 13032491\n",
      "Total completion tokens: 92622\n",
      "2.01044685\n"
     ]
    }
   ],
   "source": [
    "print(\"Total prompt tokens:\", global_prompt_tokens)\n",
    "print(\"Total completion tokens:\", global_completion_tokens)\n",
    "print(costs(global_prompt_tokens, global_completion_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations count:\n",
      "10: 40\n"
     ]
    }
   ],
   "source": [
    "with open(results, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# print the number of how many times each iteration was used\n",
    "iterations_count = {}\n",
    "for result in data:\n",
    "    iterations = result['metadata']['iterations']\n",
    "    if iterations not in iterations_count:\n",
    "        iterations_count[iterations] = 0\n",
    "    iterations_count[iterations] += 1\n",
    "print(\"Iterations count:\")\n",
    "for iterations, count in iterations_count.items():\n",
    "    print(f\"{iterations}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
